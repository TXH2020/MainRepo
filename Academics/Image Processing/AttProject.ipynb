{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOuULIeByJv3rsbMczqJM1s",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TXH2020/MainRepo/blob/main/Academics/Image%20Processing/AttProject.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade -q gspread\n",
        "!pip install face_recognition\n",
        "!pip install --upgrade --no-cache-dir gdown"
      ],
      "metadata": {
        "id": "4--7SyQd9tiy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c812712f-be3c-460a-b8c7-52724eb5da94"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting face_recognition\n",
            "  Downloading face_recognition-1.3.0-py2.py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from face_recognition) (7.1.2)\n",
            "Collecting face-recognition-models>=0.3.0\n",
            "  Downloading face_recognition_models-0.3.0.tar.gz (100.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 100.1 MB 23 kB/s \n",
            "\u001b[?25hRequirement already satisfied: dlib>=19.7 in /usr/local/lib/python3.7/dist-packages (from face_recognition) (19.24.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from face_recognition) (1.21.6)\n",
            "Requirement already satisfied: Click>=6.0 in /usr/local/lib/python3.7/dist-packages (from face_recognition) (7.1.2)\n",
            "Building wheels for collected packages: face-recognition-models\n",
            "  Building wheel for face-recognition-models (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for face-recognition-models: filename=face_recognition_models-0.3.0-py2.py3-none-any.whl size=100566185 sha256=ad586c7602cfc5a95c4e29f5c3d4938c8edfa871ef7aca3ad242c0465516d627\n",
            "  Stored in directory: /root/.cache/pip/wheels/d6/81/3c/884bcd5e1c120ff548d57c2ecc9ebf3281c9a6f7c0e7e7947a\n",
            "Successfully built face-recognition-models\n",
            "Installing collected packages: face-recognition-models, face-recognition\n",
            "Successfully installed face-recognition-1.3.0 face-recognition-models-0.3.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: gdown in /usr/local/lib/python3.7/dist-packages (4.4.0)\n",
            "Collecting gdown\n",
            "  Downloading gdown-4.5.3.tar.gz (14 kB)\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.7/dist-packages (from gdown) (4.6.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from gdown) (1.15.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from gdown) (4.64.1)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.7/dist-packages (from gdown) (2.23.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from gdown) (3.8.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->gdown) (2022.9.24)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->gdown) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->gdown) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->gdown) (1.24.3)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->gdown) (1.7.1)\n",
            "Building wheels for collected packages: gdown\n",
            "  Building wheel for gdown (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gdown: filename=gdown-4.5.3-py3-none-any.whl size=14840 sha256=efdd89f54cc644f6c20ab9051d83451d332d4cc3cae534e4e5c44905e0233bc3\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-_uow673d/wheels/94/8d/0b/bdcd83555c3555f91a33f6c2384428d9f163c7d75ab0d272b4\n",
            "Successfully built gdown\n",
            "Installing collected packages: gdown\n",
            "  Attempting uninstall: gdown\n",
            "    Found existing installation: gdown 4.4.0\n",
            "    Uninstalling gdown-4.4.0:\n",
            "      Successfully uninstalled gdown-4.4.0\n",
            "Successfully installed gdown-4.5.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import gspread\n",
        "import pandas as pd\n",
        "from google.colab import auth\n",
        "from google.colab import drive\n",
        "from google.auth import default\n",
        "import pickle\n",
        "import os\n",
        "import gdown\n",
        "\n",
        "auth.authenticate_user()\n",
        "creds, _ = default()\n",
        "gc = gspread.authorize(creds)\n",
        "worksheet_name='Database Of Face Photos (Responses)'\n",
        "worksheet = gc.open(worksheet_name).sheet1\n",
        "rows = worksheet.get_all_values()\n",
        "df=pd.DataFrame.from_records(rows,columns=rows[0],nrows=1)\n",
        "df1=df.drop(0)\n",
        "df1.reset_index\n",
        "df1.set_index(np.arange(0,len(rows)-1),inplace=True)\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "fTdEfZwXa022",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8822e6b2-3791-4767-f3ad-2d61f0c94768"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import face_recognition\n",
        "from PIL import Image\n",
        "# Load the jpg files into numpy arrays\n",
        "def encoding(df,face_encoding):\n",
        "  known_image=[]\n",
        "  for i in range(df.shape[0]):\n",
        "    known_image.append(face_recognition.load_image_file(df['NAME'][i]+\".jpg\"))\n",
        "\n",
        "# Get the face encodings for each face in each image file\n",
        "# Since there could be more than one face in each image, it returns a list of encodings.\n",
        "# But since I know each image only has one face, I only care about the first encoding in each image, so I grab index 0.\n",
        "  for i in range(df.shape[0]):\n",
        "    try:\n",
        "      print(i)\n",
        "      face_encoding.append(face_recognition.face_encodings(known_image[i],model='cnn')[0])\n",
        "  #unknown_face_encoding = face_recognition.face_encodings(unknown_image,model='cnn')\n",
        "    except IndexError:\n",
        "      im1=Image.open(df['NAME'][i]+\".jpg\")\n",
        "      im2=im1.copy().rotate(270)\n",
        "      im2.save('check.jpg')\n",
        "      error_image=face_recognition.load_image_file(\"check.jpg\")\n",
        "      try:\n",
        "        face_encoding.append(face_recognition.face_encodings(error_image,model='cnn')[0])\n",
        "      except:\n",
        "        im1=Image.open('check.jpg')\n",
        "        im2=im1.copy().rotate(180)\n",
        "        im2.save('check1.jpg')\n",
        "        error_image1=face_recognition.load_image_file(\"check1.jpg\")\n",
        "        face_encoding.append(face_recognition.face_encodings(error_image1,model='cnn')[0])\n",
        "  store_data(face_encoding)\n",
        "\n",
        "  #l=[0 for i in range(len(face_encoding))]\n",
        "\"\"\"for i in range(len(unknown_face_encoding)):\n",
        "  result=face_recognition.compare_faces(face_encoding, unknown_face_encoding[i],tolerance=0.54)\n",
        "  if(True in result):\n",
        "    l[result.index(True)]=1\n",
        "for i in range(len(l)):\n",
        "  if(l[i]==1):\n",
        "    print(known_names[i], \" is Present\")\n",
        "  else:\n",
        "    print(known_names[i], \" is Absent\")\"\"\""
      ],
      "metadata": {
        "id": "vvGlx_Q8pj8A",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "61315799-c31f-4734-a633-7c0e69bbb45c"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'for i in range(len(unknown_face_encoding)):\\n  result=face_recognition.compare_faces(face_encoding, unknown_face_encoding[i],tolerance=0.54)\\n  if(True in result):\\n    l[result.index(True)]=1\\nfor i in range(len(l)):\\n  if(l[i]==1):\\n    print(known_names[i], \" is Present\")\\n  else:\\n    print(known_names[i], \" is Absent\")'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def download_photos(df,l1):\n",
        " for i in range(df.shape[0]):\n",
        "  print(i)\n",
        "  a=df['Your Photo'][i]\n",
        "  file_id=a[a.find('=')+1:]\n",
        "  url=\"https://drive.google.com/uc?id={}\".format(file_id)\n",
        "  gdown.download(url, df['NAME'][i]+\".jpg\", quiet=True)\n",
        " encoding(df,l1)"
      ],
      "metadata": {
        "id": "X22zgijRDgbb"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def store_data(face_encoding):\n",
        "  %cd drive/MyDrive\n",
        "  with open(worksheet_name+'.pkl','wb') as p:\n",
        "    pickle.dump(face_encoding,p)\n",
        "  %cd /content"
      ],
      "metadata": {
        "id": "7mxmizuRXqXM"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if(os.path.isfile('drive/MyDrive/'+worksheet_name+'.pkl')==False):\n",
        "  download_photos(df1,[])\n",
        "\n",
        "%cd drive/MyDrive\n",
        "with open(worksheet_name+'.pkl','rb') as p:\n",
        "    face_encoding=pickle.load(p)\n",
        "%cd /content\n",
        "\n",
        "if(len(face_encoding)<df1.shape[0]):\n",
        "  download_photos(df1.iloc[len(face_encoding):],face_encoding)"
      ],
      "metadata": {
        "id": "TfHnYW4HCml7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "34755ca6-749b-4db8-e89c-8a3687ba5132"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive\n",
            "/content\n"
          ]
        }
      ]
    }
  ]
}
